{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae222ba9",
   "metadata": {
    "papermill": {
     "duration": 0.004527,
     "end_time": "2025-02-25T16:42:16.680971",
     "exception": false,
     "start_time": "2025-02-25T16:42:16.676444",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Introduction:**  \n",
    "In this notebook we integrated insights from our comprehensive EDA and prior winning solutions into a competitive submission pipeline for NCAA March Machine Learning Mania 2025. We computed Elo ratings (trained on seasons before 2024), prepared training data for margin modeling, trained separate KNN regressors for men's and women's data, and converted margin predictions to win probabilities.\n",
    " \n",
    "**Validation:**  \n",
    "We simulated a hold‐out validation on the 2024 regular season detailed results by predicting game outcomes and calculating the Brier score. This gave us an indication of our model’s predictive performance using the same competition metric.\n",
    " \n",
    "**Key Takeaways:**  \n",
    " - The refreshed data (up to DayNum 106 for regular season and updated Massey Ordinals) is now reliable with fixed issues.  \n",
    " - Separately modeling men's and women's games is essential due to inherent scoring differences.  \n",
    " - Our two‑stage approach—computing Elo ratings and then modeling margin differences using KNN—translates well into win probability predictions.  \n",
    " - Validation on 2024 data provides a realistic measure of model performance before final submissions.\n",
    " \n",
    "**Conclusion:**  \n",
    "This complete pipeline not only generates competitive submissions (with the ability to produce 100 variants for ensembling) but also validates performance on recent data. Future improvements might include incorporating ensemble methods, alternate models such as XGBoost with GPU support, or additional features inspired by past winning solutions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c2d8670",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-02-25T16:42:16.690313Z",
     "iopub.status.busy": "2025-02-25T16:42:16.689894Z",
     "iopub.status.idle": "2025-02-25T16:42:22.889394Z",
     "shell.execute_reply": "2025-02-25T16:42:22.888088Z"
    },
    "papermill": {
     "duration": 6.205958,
     "end_time": "2025-02-25T16:42:22.891090",
     "exception": false,
     "start_time": "2025-02-25T16:42:16.685132",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported and default styles set.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sns.set(style=\"whitegrid\", context=\"notebook\", font_scale=1.1)\n",
    "\n",
    "print(\"Libraries imported and default styles set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "632ff98e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T16:42:22.901225Z",
     "iopub.status.busy": "2025-02-25T16:42:22.900553Z",
     "iopub.status.idle": "2025-02-25T16:42:29.062685Z",
     "shell.execute_reply": "2025-02-25T16:42:29.061570Z"
    },
    "papermill": {
     "duration": 6.169127,
     "end_time": "2025-02-25T16:42:29.064443",
     "exception": false,
     "start_time": "2025-02-25T16:42:22.895316",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Conferences with shape (51, 2)\n",
      "Loaded SeedBenchmarkStage1 with shape (507108, 2)\n",
      "Loaded WNCAATourneyDetailedResults with shape (894, 34)\n",
      "Loaded WRegularSeasonCompactResults with shape (135948, 8)\n",
      "Loaded MNCAATourneySeedRoundSlots with shape (776, 5)\n",
      "Loaded MRegularSeasonDetailedResults with shape (117748, 34)\n",
      "Loaded MNCAATourneyCompactResults with shape (2518, 8)\n",
      "Loaded MGameCities with shape (85534, 6)\n",
      "Loaded WSecondaryTourneyCompactResults with shape (828, 9)\n",
      "Loaded WGameCities with shape (82329, 6)\n",
      "Loaded MSeasons with shape (41, 6)\n",
      "Loaded WNCAATourneySlots with shape (1713, 4)\n",
      "Loaded MSecondaryTourneyTeams with shape (1836, 3)\n",
      "Loaded SampleSubmissionStage2 with shape (131407, 2)\n",
      "Loaded Cities with shape (502, 3)\n",
      "Loaded MTeamSpellings with shape (1177, 2)\n",
      "Loaded MRegularSeasonCompactResults with shape (191796, 8)\n",
      "Loaded MMasseyOrdinals with shape (5489117, 5)\n",
      "Loaded MSecondaryTourneyCompactResults with shape (1809, 9)\n",
      "Loaded WTeams with shape (378, 2)\n",
      "Loaded WConferenceTourneyGames with shape (6113, 5)\n",
      "Loaded MNCAATourneySlots with shape (2519, 4)\n",
      "Loaded MNCAATourneySeeds with shape (2558, 3)\n",
      "Loaded WNCAATourneyCompactResults with shape (1650, 8)\n",
      "Loaded WSeasons with shape (28, 6)\n",
      "Loaded WNCAATourneySeeds with shape (1676, 3)\n",
      "Loaded MTeamCoaches with shape (13533, 5)\n",
      "Loaded MConferenceTourneyGames with shape (6491, 5)\n",
      "Loaded WRegularSeasonDetailedResults with shape (80626, 34)\n",
      "Loaded MNCAATourneyDetailedResults with shape (1382, 34)\n",
      "Loaded WTeamSpellings with shape (1170, 2)\n",
      "Loaded MTeamConferences with shape (13388, 3)\n",
      "Loaded MTeams with shape (380, 4)\n",
      "Loaded WTeamConferences with shape (9490, 3)\n",
      "Loaded SampleSubmissionStage1 with shape (507108, 2)\n",
      "Loaded WSecondaryTourneyTeams with shape (824, 3)\n",
      "\n",
      "All CSV files loaded automatically.\n"
     ]
    }
   ],
   "source": [
    "# Define the input folder path\n",
    "input_folder = r\"/kaggle/input/march-machine-learning-mania-2025\"\n",
    "\n",
    "# Find all CSV files in the input folder.\n",
    "csv_files = glob.glob(os.path.join(input_folder, \"*.csv\"))\n",
    "\n",
    "# Create a dictionary to store DataFrames.\n",
    "dataframes = {}\n",
    "\n",
    "# Loop through each CSV file, read it, and store it in the dictionary using the filename (without extension) as the key.\n",
    "for file in csv_files:\n",
    "    key = os.path.splitext(os.path.basename(file))[0]\n",
    "    try:\n",
    "        dataframes[key] = pd.read_csv(file, low_memory=False, encoding=\"latin-1\")\n",
    "        print(f\"Loaded {key} with shape {dataframes[key].shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file}: {e}\")\n",
    "\n",
    "print(\"\\nAll CSV files loaded automatically.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7e54bd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T16:42:29.075060Z",
     "iopub.status.busy": "2025-02-25T16:42:29.074694Z",
     "iopub.status.idle": "2025-02-25T16:42:29.527830Z",
     "shell.execute_reply": "2025-02-25T16:42:29.526091Z"
    },
    "papermill": {
     "duration": 0.460426,
     "end_time": "2025-02-25T16:42:29.529654",
     "exception": false,
     "start_time": "2025-02-25T16:42:29.069228",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Stage 2 sample submission.\n",
      "Sample submission file prepared:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Pred</th>\n",
       "      <th>Season</th>\n",
       "      <th>Team1</th>\n",
       "      <th>Team2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025_1101_1102</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2025</td>\n",
       "      <td>1101</td>\n",
       "      <td>1102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025_1101_1103</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2025</td>\n",
       "      <td>1101</td>\n",
       "      <td>1103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025_1101_1104</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2025</td>\n",
       "      <td>1101</td>\n",
       "      <td>1104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID  Pred  Season  Team1  Team2\n",
       "0  2025_1101_1102   0.5    2025   1101   1102\n",
       "1  2025_1101_1103   0.5    2025   1101   1103\n",
       "2  2025_1101_1104   0.5    2025   1101   1104"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use Stage 2 sample submission if available; otherwise, use Stage1.\n",
    "if 'SampleSubmissionStage2' in dataframes:\n",
    "    df_sub = dataframes['SampleSubmissionStage2'].copy()\n",
    "    print(\"Using Stage 2 sample submission.\")\n",
    "else:\n",
    "    df_sub = dataframes['SampleSubmissionStage1'].copy()\n",
    "    print(\"Stage 2 not found. Using Stage 1 sample submission.\")\n",
    "\n",
    "def parse_id(match_id):\n",
    "    season, t1, t2 = match_id.split('_')\n",
    "    return int(season), int(t1), int(t2)\n",
    "\n",
    "df_sub['Season'] = df_sub['ID'].apply(lambda x: parse_id(x)[0])\n",
    "df_sub['Team1'] = df_sub['ID'].apply(lambda x: parse_id(x)[1])\n",
    "df_sub['Team2'] = df_sub['ID'].apply(lambda x: parse_id(x)[2])\n",
    "print(\"Sample submission file prepared:\")\n",
    "display(df_sub.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4ffe1e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T16:42:29.540637Z",
     "iopub.status.busy": "2025-02-25T16:42:29.540264Z",
     "iopub.status.idle": "2025-02-25T16:42:29.547294Z",
     "shell.execute_reply": "2025-02-25T16:42:29.546111Z"
    },
    "papermill": {
     "duration": 0.014504,
     "end_time": "2025-02-25T16:42:29.549149",
     "exception": false,
     "start_time": "2025-02-25T16:42:29.534645",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def initialize_elo(team_ids, start_elo=1500):\n",
    "    return {tid: start_elo for tid in team_ids}\n",
    "\n",
    "def update_elo(elo_dict, teamA, teamB, scoreA, scoreB, k=20):\n",
    "    ra = elo_dict[teamA]\n",
    "    rb = elo_dict[teamB]\n",
    "    ea = 1.0 / (1 + 10 ** ((rb - ra) / 400))\n",
    "    # Actual result: 1 if teamA wins, 0 if teamB wins.\n",
    "    sa = 1 if scoreA > scoreB else 0\n",
    "    elo_dict[teamA] = ra + k * (sa - ea)\n",
    "    elo_dict[teamB] = rb + k * ((1 - sa) - (1 - ea))\n",
    "\n",
    "def compute_elo(df_games, teams_df):\n",
    "    df_sorted = df_games.sort_values(by=['Season','DayNum'])\n",
    "    team_ids = teams_df['TeamID'].unique()\n",
    "    elo_dict = initialize_elo(team_ids)\n",
    "    for idx, row in df_sorted.iterrows():\n",
    "        update_elo(elo_dict, row['WTeamID'], row['LTeamID'], row['WScore'], row['LScore'])\n",
    "    return elo_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0b2e9d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T16:42:29.560138Z",
     "iopub.status.busy": "2025-02-25T16:42:29.559767Z",
     "iopub.status.idle": "2025-02-25T16:42:40.007101Z",
     "shell.execute_reply": "2025-02-25T16:42:40.005648Z"
    },
    "papermill": {
     "duration": 10.454862,
     "end_time": "2025-02-25T16:42:40.009016",
     "exception": false,
     "start_time": "2025-02-25T16:42:29.554154",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elo ratings computed using seasons before 2024 for men's and women's data.\n"
     ]
    }
   ],
   "source": [
    "# Filter men's and women's regular season detailed results:\n",
    "df_MReg = dataframes['MRegularSeasonDetailedResults']\n",
    "df_WReg = dataframes['WRegularSeasonDetailedResults']\n",
    "\n",
    "# Use only seasons before 2024 for training Elo ratings.\n",
    "df_MReg_train = df_MReg[df_MReg['Season'] < 2024].copy()\n",
    "df_WReg_train = df_WReg[df_WReg['Season'] < 2024].copy()\n",
    "\n",
    "# Get team lists.\n",
    "df_MTeams = dataframes['MTeams']\n",
    "df_WTeams = dataframes['WTeams']\n",
    "\n",
    "elo_m_train = compute_elo(df_MReg_train, df_MTeams)\n",
    "elo_w_train = compute_elo(df_WReg_train, df_WTeams)\n",
    "print(\"Elo ratings computed using seasons before 2024 for men's and women's data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92859e26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T16:42:40.020233Z",
     "iopub.status.busy": "2025-02-25T16:42:40.019785Z",
     "iopub.status.idle": "2025-02-25T16:42:50.150240Z",
     "shell.execute_reply": "2025-02-25T16:42:50.149008Z"
    },
    "papermill": {
     "duration": 10.138266,
     "end_time": "2025-02-25T16:42:50.152372",
     "exception": false,
     "start_time": "2025-02-25T16:42:40.014106",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data prepared for men's and women's margin models.\n"
     ]
    }
   ],
   "source": [
    "def prepare_training_data(df, elo_dict):\n",
    "    elo_diffs = []\n",
    "    margins = []\n",
    "    for idx, row in df.iterrows():\n",
    "        diff = elo_dict.get(row['WTeamID'], 1500) - elo_dict.get(row['LTeamID'], 1500)\n",
    "        elo_diffs.append(diff)\n",
    "        margins.append(row['WScore'] - row['LScore'])\n",
    "    return pd.DataFrame({'EloDiff': elo_diffs, 'Margin': margins})\n",
    "\n",
    "train_m = prepare_training_data(df_MReg_train, elo_m_train)\n",
    "train_w = prepare_training_data(df_WReg_train, elo_w_train)\n",
    "print(\"Training data prepared for men's and women's margin models.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e0dd11b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T16:42:50.163738Z",
     "iopub.status.busy": "2025-02-25T16:42:50.163356Z",
     "iopub.status.idle": "2025-02-25T16:42:56.060248Z",
     "shell.execute_reply": "2025-02-25T16:42:56.059236Z"
    },
    "papermill": {
     "duration": 5.904428,
     "end_time": "2025-02-25T16:42:56.061925",
     "exception": false,
     "start_time": "2025-02-25T16:42:50.157497",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best n_neighbors: {'n_neighbors': 40}\n",
      "Best n_neighbors: {'n_neighbors': 40}\n",
      "KNN margin models trained for men's and women's data.\n"
     ]
    }
   ],
   "source": [
    "def train_margin_model(df_train):\n",
    "    X = df_train[['EloDiff']].values\n",
    "    y = df_train['Margin'].values\n",
    "    knn = KNeighborsRegressor()\n",
    "    param_grid = {'n_neighbors': [5, 7, 10, 13, 20, 27, 37, 40]}\n",
    "    gscv = GridSearchCV(knn, param_grid, cv=3, scoring='neg_mean_squared_error')\n",
    "    gscv.fit(X, y)\n",
    "    print(\"Best n_neighbors:\", gscv.best_params_)\n",
    "    return gscv.best_estimator_\n",
    "\n",
    "knn_m = train_margin_model(train_m)\n",
    "knn_w = train_margin_model(train_w)\n",
    "print(\"KNN margin models trained for men's and women's data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e11a0bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T16:42:56.073253Z",
     "iopub.status.busy": "2025-02-25T16:42:56.072823Z",
     "iopub.status.idle": "2025-02-25T16:42:56.079683Z",
     "shell.execute_reply": "2025-02-25T16:42:56.078612Z"
    },
    "papermill": {
     "duration": 0.014357,
     "end_time": "2025-02-25T16:42:56.081431",
     "exception": false,
     "start_time": "2025-02-25T16:42:56.067074",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def margin_to_probability(margin, scale=10.0):\n",
    "    return 1.0 / (1 + 10 ** (-margin / scale))\n",
    "\n",
    "def predict_match(row, elo_m, elo_w, knn_m, knn_w):\n",
    "    # For competition submissions, the prediction is for the team with the lower TeamID.\n",
    "    team1, team2 = row['Team1'], row['Team2']\n",
    "    if team1 < team2:\n",
    "        lower = team1\n",
    "        higher = team2\n",
    "    else:\n",
    "        lower = team2\n",
    "        higher = team1\n",
    "        \n",
    "    # Determine bracket based on team IDs.\n",
    "    if lower < 2000 and higher < 2000:\n",
    "        e_lower = elo_m.get(lower, 1500)\n",
    "        e_higher = elo_m.get(higher, 1500)\n",
    "        elo_diff = e_lower - e_higher\n",
    "        margin_pred = knn_m.predict(np.array([[elo_diff]]))[0]\n",
    "        prob = margin_to_probability(margin_pred)\n",
    "    elif lower >= 3000 and higher >= 3000:\n",
    "        e_lower = elo_w.get(lower, 1500)\n",
    "        e_higher = elo_w.get(higher, 1500)\n",
    "        elo_diff = e_lower - e_higher\n",
    "        margin_pred = knn_w.predict(np.array([[elo_diff]]))[0]\n",
    "        prob = margin_to_probability(margin_pred)\n",
    "    else:\n",
    "        prob = 0.5  # Default case (should not occur)\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7827e9e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T16:42:56.092715Z",
     "iopub.status.busy": "2025-02-25T16:42:56.092377Z",
     "iopub.status.idle": "2025-02-25T16:42:56.104451Z",
     "shell.execute_reply": "2025-02-25T16:42:56.103561Z"
    },
    "papermill": {
     "duration": 0.019805,
     "end_time": "2025-02-25T16:42:56.106307",
     "exception": false,
     "start_time": "2025-02-25T16:42:56.086502",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_actual_outcome(row):\n",
    "    # Outcome is 1 if the team with lower ID won (i.e. equals WTeamID), else 0.\n",
    "    team1, team2 = row['WTeamID'], row['LTeamID']\n",
    "    lower = min(team1, team2)\n",
    "    return 1 if lower == row['WTeamID'] else 0\n",
    "\n",
    "# For men's validation: Use MRegularSeasonDetailedResults from season 2024.\n",
    "df_MReg_val = df_MReg[df_MReg['Season'] == 2024].copy()\n",
    "# For women's validation: Use WRegularSeasonDetailedResults from season 2024.\n",
    "df_WReg_val = df_WReg[df_WReg['Season'] == 2024].copy()\n",
    "\n",
    "# Compute predictions for validation games.\n",
    "def validate_games(df_val, elo_dict, knn_model):\n",
    "    preds = []\n",
    "    actuals = []\n",
    "    for idx, row in df_val.iterrows():\n",
    "        # For validation, always predict for the team with lower ID.\n",
    "        team1, team2 = row['WTeamID'], row['LTeamID']\n",
    "        lower = min(team1, team2)\n",
    "        # Get Elo ratings from training Elo dictionary (which did NOT use 2024)\n",
    "        if lower < 2000:\n",
    "            e_lower = elo_m_train.get(lower, 1500)\n",
    "            # For the opponent, use the rating for the higher ID.\n",
    "            e_higher = elo_m_train.get(max(team1, team2), 1500)\n",
    "            elo_diff = e_lower - e_higher\n",
    "            margin_pred = knn_m.predict(np.array([[elo_diff]]))[0]\n",
    "        else:\n",
    "            e_lower = elo_w_train.get(lower, 1500)\n",
    "            e_higher = elo_w_train.get(max(team1, team2), 1500)\n",
    "            elo_diff = e_lower - e_higher\n",
    "            margin_pred = knn_w.predict(np.array([[elo_diff]]))[0]\n",
    "        prob = margin_to_probability(margin_pred)\n",
    "        preds.append(prob)\n",
    "        # Actual outcome: 1 if the lower team wins.\n",
    "        outcome = 1 if lower == row['WTeamID'] else 0\n",
    "        actuals.append(outcome)\n",
    "    return np.array(preds), np.array(actuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2bd568c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T16:42:56.117469Z",
     "iopub.status.busy": "2025-02-25T16:42:56.117096Z",
     "iopub.status.idle": "2025-02-25T16:43:01.863753Z",
     "shell.execute_reply": "2025-02-25T16:43:01.862618Z"
    },
    "papermill": {
     "duration": 5.754129,
     "end_time": "2025-02-25T16:43:01.865539",
     "exception": false,
     "start_time": "2025-02-25T16:42:56.111410",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Men's 2024 Regular Season Brier Score: 0.41334762681136566\n",
      "Women's 2024 Regular Season Brier Score: 0.4254164948545672\n"
     ]
    }
   ],
   "source": [
    "preds_m, actuals_m = validate_games(df_MReg_val, elo_m_train, knn_m)\n",
    "preds_w, actuals_w = validate_games(df_WReg_val, elo_w_train, knn_w)\n",
    "\n",
    "# Compute Brier scores for men's and women's validation sets.\n",
    "brier_m = mean_squared_error(actuals_m, preds_m)\n",
    "brier_w = mean_squared_error(actuals_w, preds_w)\n",
    "\n",
    "print(\"Men's 2024 Regular Season Brier Score:\", brier_m)\n",
    "print(\"Women's 2024 Regular Season Brier Score:\", brier_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d11c5a18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T16:43:01.877588Z",
     "iopub.status.busy": "2025-02-25T16:43:01.877179Z",
     "iopub.status.idle": "2025-02-25T16:43:01.881260Z",
     "shell.execute_reply": "2025-02-25T16:43:01.880142Z"
    },
    "papermill": {
     "duration": 0.012169,
     "end_time": "2025-02-25T16:43:01.883054",
     "exception": false,
     "start_time": "2025-02-25T16:43:01.870885",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Create a folder to save submissions.\n",
    "# submission_folder = \"ensemble_submissions\"\n",
    "# os.makedirs(submission_folder, exist_ok=True)\n",
    "\n",
    "# num_submissions = 100\n",
    "\n",
    "# for i in range(1, num_submissions + 1):\n",
    "#     seed_val = 1000 + i\n",
    "#     print(f\"\\n=== Iteration {i} using seed {seed_val} ===\")\n",
    "    \n",
    "#     # Retrain KNN models with the new seed on the same training data.\n",
    "#     # (In a more advanced approach, you might retrain with additional hyperparameter variations.)\n",
    "#     knn_m_i = train_margin_model(train_m)\n",
    "#     knn_w_i = train_margin_model(train_w)\n",
    "    \n",
    "#     # Generate predictions for each matchup in the submission file.\n",
    "#     preds = []\n",
    "#     for idx, row in df_sub.iterrows():\n",
    "#         p = predict_match(row, elo_m_train, elo_w_train, knn_m_i, knn_w_i)\n",
    "#         # Optionally add a small random perturbation.\n",
    "#         p += np.random.normal(0, 0.005)\n",
    "#         p = np.clip(p, 0.001, 0.999)\n",
    "#         preds.append(p)\n",
    "#     df_sub['Pred'] = preds\n",
    "    \n",
    "#     submission_filename = os.path.join(submission_folder, f\"submission_{i}.csv\")\n",
    "#     df_sub[['ID', 'Pred']].to_csv(submission_filename, index=False)\n",
    "#     print(f\"Saved submission file: {submission_filename}\")\n",
    "\n",
    "# print(\"\\nEnsemble submission generation complete. 100 submission files created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48e3ef90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T16:43:01.894130Z",
     "iopub.status.busy": "2025-02-25T16:43:01.893790Z",
     "iopub.status.idle": "2025-02-25T16:44:13.227240Z",
     "shell.execute_reply": "2025-02-25T16:44:13.225925Z"
    },
    "papermill": {
     "duration": 71.345477,
     "end_time": "2025-02-25T16:44:13.233557",
     "exception": false,
     "start_time": "2025-02-25T16:43:01.888080",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions generated for all matchups. Here are a few examples:\n",
      "               ID      Pred  Season  Team1  Team2\n",
      "0  2025_1101_1102  0.889325    2025   1101   1102\n",
      "1  2025_1101_1103  0.859032    2025   1101   1103\n",
      "2  2025_1101_1104  0.873693    2025   1101   1104\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions for each matchup in df_sub.\n",
    "predictions = []\n",
    "for idx, row in df_sub.iterrows():\n",
    "    p = predict_match(row, elo_m_train, elo_w_train, knn_m, knn_w)\n",
    "    # Optionally, add a small perturbation for uncertainty.\n",
    "    p += np.random.normal(0, 0.005)\n",
    "    p = np.clip(p, 0.001, 0.999)\n",
    "    predictions.append(p)\n",
    "df_sub['Pred'] = predictions\n",
    "\n",
    "print(\"Predictions generated for all matchups. Here are a few examples:\")\n",
    "print(df_sub.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2e71778",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T16:44:13.244953Z",
     "iopub.status.busy": "2025-02-25T16:44:13.244585Z",
     "iopub.status.idle": "2025-02-25T16:44:13.530681Z",
     "shell.execute_reply": "2025-02-25T16:44:13.529338Z"
    },
    "papermill": {
     "duration": 0.294052,
     "end_time": "2025-02-25T16:44:13.532684",
     "exception": false,
     "start_time": "2025-02-25T16:44:13.238632",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file 'submission.csv' created successfully.\n"
     ]
    }
   ],
   "source": [
    "# %% [code]\n",
    "submission_filename = \"submission.csv\"\n",
    "df_sub[['ID', 'Pred']].to_csv(submission_filename, index=False)\n",
    "print(f\"Submission file '{submission_filename}' created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecb8ea2",
   "metadata": {
    "papermill": {
     "duration": 0.005229,
     "end_time": "2025-02-25T16:44:13.543473",
     "exception": false,
     "start_time": "2025-02-25T16:44:13.538244",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 11165145,
     "sourceId": 91497,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30886,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 120.864661,
   "end_time": "2025-02-25T16:44:14.572178",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-25T16:42:13.707517",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
